"""Stage question generator node for deep interview system.

Generates dynamic, context-aware questions for each interview stage.
Questions are generated by AI based on topic, mode, and previous answers.
"""
import json
from typing import List, Optional
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import HumanMessage

from app.config import settings
from app.ai.state import (
    DeepInterviewState,
    InterviewQuestionData,
    StageData,
)
from app.ai.prompts.interview_prompts import (
    STAGE_1_QUESTIONS_PROMPT,
    STAGE_2_QUESTIONS_PROMPT,
    STAGE_3_QUESTIONS_PROMPT,
    get_mode_description,
)
from app.ai.nodes.answer_evaluator import format_answers_summary


def create_llm():
    return ChatAnthropic(
        model="claude-sonnet-4-5-20250929",
        anthropic_api_key=settings.anthropic_api_key,
        temperature=0.7,  # Higher temperature for more creative questions
    )


def _get_stage_summary(state: DeepInterviewState, stage_num: int) -> str:
    """Get formatted summary of a completed stage's Q&A."""
    stage_data = state.get("stage_data", {}).get(stage_num)
    if not stage_data:
        return "이전 답변 없음"

    all_questions = stage_data.get("questions", []) + stage_data.get("followup_questions", [])
    all_answers = stage_data.get("answers", []) + stage_data.get("followup_answers", [])

    return format_answers_summary(all_questions, all_answers)


def _generate_stage_1_questions(state: DeepInterviewState) -> List[InterviewQuestionData]:
    """Generate Stage 1 (Goal Clarification) questions."""
    llm = create_llm()

    prompt = STAGE_1_QUESTIONS_PROMPT.format(
        topic=state["topic"],
        mode=state["mode"],
        mode_description=get_mode_description(state["mode"]),
        duration_months=state["duration_months"],
    )

    try:
        response = llm.invoke([HumanMessage(content=prompt)])
        result = json.loads(response.content)

        questions = []
        for q in result.get("questions", []):
            questions.append(InterviewQuestionData(
                id=q.get("id", f"stage1_{len(questions)}"),
                question=q.get("question", ""),
                question_type=q.get("question_type", "text"),
                options=q.get("options"),
                placeholder=q.get("placeholder"),
            ))

        return questions

    except (json.JSONDecodeError, KeyError) as e:
        # Fallback questions if AI generation fails
        return [
            InterviewQuestionData(
                id="goal_1",
                question=f"{state['topic']}을(를) 통해 무엇을 이루고 싶으신가요?",
                question_type="text",
                options=None,
                placeholder="구체적인 목표를 알려주세요",
            ),
            InterviewQuestionData(
                id="goal_2",
                question="이 목표가 지금 중요한 이유는 무엇인가요?",
                question_type="text",
                options=None,
                placeholder="동기나 배경을 알려주세요",
            ),
        ]


def _generate_stage_2_questions(state: DeepInterviewState) -> List[InterviewQuestionData]:
    """Generate Stage 2 (Current State) questions based on Stage 1 answers."""
    llm = create_llm()

    stage1_summary = _get_stage_summary(state, 1)

    prompt = STAGE_2_QUESTIONS_PROMPT.format(
        topic=state["topic"],
        mode=state["mode"],
        duration_months=state["duration_months"],
        stage1_summary=stage1_summary,
    )

    try:
        response = llm.invoke([HumanMessage(content=prompt)])
        result = json.loads(response.content)

        questions = []
        for q in result.get("questions", []):
            questions.append(InterviewQuestionData(
                id=q.get("id", f"stage2_{len(questions)}"),
                question=q.get("question", ""),
                question_type=q.get("question_type", "text"),
                options=q.get("options"),
                placeholder=q.get("placeholder"),
            ))

        return questions

    except (json.JSONDecodeError, KeyError) as e:
        # Fallback questions
        return [
            InterviewQuestionData(
                id="current_1",
                question=f"{state['topic']} 관련 현재 수준은 어느 정도인가요?",
                question_type="single_choice",
                options=["입문 (처음 접함)", "초급 (기초 지식 있음)", "중급 (실습 경험 있음)", "고급 (실무 경험 있음)"],
                placeholder=None,
            ),
            InterviewQuestionData(
                id="current_2",
                question="이 분야에서 이미 해본 것이 있다면 알려주세요.",
                question_type="text",
                options=None,
                placeholder="경험이나 시도해본 것들",
            ),
        ]


def _generate_stage_3_questions(state: DeepInterviewState) -> List[InterviewQuestionData]:
    """Generate Stage 3 (Constraints) questions based on Stage 1 & 2 answers."""
    llm = create_llm()

    stage1_summary = _get_stage_summary(state, 1)
    stage2_summary = _get_stage_summary(state, 2)

    prompt = STAGE_3_QUESTIONS_PROMPT.format(
        topic=state["topic"],
        mode=state["mode"],
        duration_months=state["duration_months"],
        stage1_summary=stage1_summary,
        stage2_summary=stage2_summary,
    )

    try:
        response = llm.invoke([HumanMessage(content=prompt)])
        result = json.loads(response.content)

        questions = []
        for q in result.get("questions", []):
            questions.append(InterviewQuestionData(
                id=q.get("id", f"stage3_{len(questions)}"),
                question=q.get("question", ""),
                question_type=q.get("question_type", "text"),
                options=q.get("options"),
                placeholder=q.get("placeholder"),
            ))

        return questions

    except (json.JSONDecodeError, KeyError) as e:
        # Fallback with required constraint questions
        return [
            InterviewQuestionData(
                id="constraint_daily_time",
                question="하루에 학습에 투자할 수 있는 시간은 얼마나 되나요?",
                question_type="single_choice",
                options=["30분 이하", "30분~1시간", "1~2시간", "2~3시간", "3시간 이상"],
                placeholder=None,
            ),
            InterviewQuestionData(
                id="constraint_rest_days",
                question="쉬는 날은 언제로 하시겠어요?",
                question_type="single_choice",
                options=["쉬는 날 없음 (매일 학습)", "주말만 휴식 (토,일)", "일요일만 휴식", "토요일만 휴식"],
                placeholder=None,
            ),
            InterviewQuestionData(
                id="constraint_intensity",
                question="원하는 학습 강도는 어느 정도인가요?",
                question_type="single_choice",
                options=["여유롭게 (복습 중심, 천천히)", "균형있게 (적당한 속도)", "빡세게 (빠른 진도, 도전적)"],
                placeholder=None,
            ),
        ]


def generate_stage_questions(state: DeepInterviewState) -> DeepInterviewState:
    """Generate questions for the current stage.

    This node generates dynamic, context-aware questions based on:
    - The topic and mode
    - Previous stage answers (for stages 2 and 3)
    - AI's understanding of what information is still needed
    """
    current_stage = state["current_stage"]

    # Generate questions based on current stage
    if current_stage == 1:
        questions = _generate_stage_1_questions(state)
    elif current_stage == 2:
        questions = _generate_stage_2_questions(state)
    elif current_stage == 3:
        questions = _generate_stage_3_questions(state)
    else:
        questions = []

    # Update state
    state["current_questions"] = questions
    state["current_answers"] = []
    state["current_evaluations"] = []
    state["followup_count"] = 0
    state["pending_followup_questions"] = []

    return state


def generate_followup_questions(state: DeepInterviewState) -> DeepInterviewState:
    """Prepare follow-up questions from pending list.

    This node moves pending follow-up questions to current questions
    so the user can answer them.
    """
    pending = state.get("pending_followup_questions", [])

    if pending:
        # Move pending follow-ups to current questions
        state["current_questions"] = pending
        state["current_answers"] = []
        state["current_evaluations"] = []
        state["pending_followup_questions"] = []
        state["followup_count"] = state.get("followup_count", 0) + 1

    return state


def advance_to_next_stage(state: DeepInterviewState) -> DeepInterviewState:
    """Save current stage data and advance to the next stage.

    This node:
    1. Saves all Q&A from current stage to stage_data
    2. Increments current_stage
    3. Resets current stage working variables
    """
    current_stage = state["current_stage"]

    # Initialize stage_data if needed
    if "stage_data" not in state or state["stage_data"] is None:
        state["stage_data"] = {}

    # Save current stage data
    state["stage_data"][current_stage] = StageData(
        questions=state.get("current_questions", []),
        answers=state.get("current_answers", []),
        evaluations=state.get("current_evaluations", []),
        followup_questions=[],  # Follow-ups are already included in questions/answers
        followup_answers=[],
    )

    # Mark stage as completed
    if "stages_completed" not in state or state["stages_completed"] is None:
        state["stages_completed"] = []
    state["stages_completed"].append(current_stage)

    # Advance to next stage
    state["current_stage"] = current_stage + 1

    # Reset current stage variables
    state["current_questions"] = []
    state["current_answers"] = []
    state["current_evaluations"] = []
    state["followup_count"] = 0
    state["pending_followup_questions"] = []

    return state
